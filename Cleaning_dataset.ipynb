{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset=pd.read_csv('attacks.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first sight we can see a 23 columns dataset. Some of them are dates, some of them are categorical data and links to files than can be useful if important information is missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>AdysonÂ McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Arrawarra Headland</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>2018.06.08-Arrawarra.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Colima</td>\n",
       "      <td>La Ticla</td>\n",
       "      <td>Free diving</td>\n",
       "      <td>Gustavo Ramos</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>Tiger shark, 3m</td>\n",
       "      <td>A .Kipper</td>\n",
       "      <td>2018.06.04-Ramos.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25718</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25719</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25720</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25721</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>xx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25723 rows Ã 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case Number         Date    Year        Type    Country  \\\n",
       "0      2018.06.25  25-Jun-2018  2018.0     Boating        USA   \n",
       "1      2018.06.18  18-Jun-2018  2018.0  Unprovoked        USA   \n",
       "2      2018.06.09  09-Jun-2018  2018.0     Invalid        USA   \n",
       "3      2018.06.08  08-Jun-2018  2018.0  Unprovoked  AUSTRALIA   \n",
       "4      2018.06.04  04-Jun-2018  2018.0    Provoked     MEXICO   \n",
       "...           ...          ...     ...         ...        ...   \n",
       "25718         NaN          NaN     NaN         NaN        NaN   \n",
       "25719         NaN          NaN     NaN         NaN        NaN   \n",
       "25720         NaN          NaN     NaN         NaN        NaN   \n",
       "25721         NaN          NaN     NaN         NaN        NaN   \n",
       "25722          xx          NaN     NaN         NaN        NaN   \n",
       "\n",
       "                  Area                        Location     Activity  \\\n",
       "0           California     Oceanside, San Diego County     Paddling   \n",
       "1              Georgia  St. Simon Island, Glynn County     Standing   \n",
       "2               Hawaii                    Habush, Oahu      Surfing   \n",
       "3      New South Wales              Arrawarra Headland      Surfing   \n",
       "4               Colima                        La Ticla  Free diving   \n",
       "...                ...                             ...          ...   \n",
       "25718              NaN                             NaN          NaN   \n",
       "25719              NaN                             NaN          NaN   \n",
       "25720              NaN                             NaN          NaN   \n",
       "25721              NaN                             NaN          NaN   \n",
       "25722              NaN                             NaN          NaN   \n",
       "\n",
       "                  Name Sex   ...         Species   \\\n",
       "0          Julie Wolfe    F  ...      White shark   \n",
       "1      AdysonÂ McNeely     F  ...              NaN   \n",
       "2          John Denges    M  ...              NaN   \n",
       "3                 male    M  ...        2 m shark   \n",
       "4       Gustavo Ramos     M  ...  Tiger shark, 3m   \n",
       "...                ...  ...  ...              ...   \n",
       "25718              NaN  NaN  ...              NaN   \n",
       "25719              NaN  NaN  ...              NaN   \n",
       "25720              NaN  NaN  ...              NaN   \n",
       "25721              NaN  NaN  ...              NaN   \n",
       "25722              NaN  NaN  ...              NaN   \n",
       "\n",
       "               Investigator or Source                       pdf  \\\n",
       "0                    R. Collier, GSAF      2018.06.25-Wolfe.pdf   \n",
       "1      K.McMurray, TrackingSharks.com    2018.06.18-McNeely.pdf   \n",
       "2      K.McMurray, TrackingSharks.com     2018.06.09-Denges.pdf   \n",
       "3                      B. Myatt, GSAF  2018.06.08-Arrawarra.pdf   \n",
       "4                           A .Kipper      2018.06.04-Ramos.pdf   \n",
       "...                               ...                       ...   \n",
       "25718                             NaN                       NaN   \n",
       "25719                             NaN                       NaN   \n",
       "25720                             NaN                       NaN   \n",
       "25721                             NaN                       NaN   \n",
       "25722                             NaN                       NaN   \n",
       "\n",
       "                                            href formula  \\\n",
       "0      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "3      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "4      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "...                                                  ...   \n",
       "25718                                                NaN   \n",
       "25719                                                NaN   \n",
       "25720                                                NaN   \n",
       "25721                                                NaN   \n",
       "25722                                                NaN   \n",
       "\n",
       "                                                    href Case Number.1  \\\n",
       "0      http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.25   \n",
       "1      http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.18   \n",
       "2      http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.09   \n",
       "3      http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.08   \n",
       "4      http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.04   \n",
       "...                                                  ...           ...   \n",
       "25718                                                NaN           NaN   \n",
       "25719                                                NaN           NaN   \n",
       "25720                                                NaN           NaN   \n",
       "25721                                                NaN           NaN   \n",
       "25722                                                NaN           NaN   \n",
       "\n",
       "      Case Number.2 original order Unnamed: 22 Unnamed: 23  \n",
       "0        2018.06.25         6303.0         NaN         NaN  \n",
       "1        2018.06.18         6302.0         NaN         NaN  \n",
       "2        2018.06.09         6301.0         NaN         NaN  \n",
       "3        2018.06.08         6300.0         NaN         NaN  \n",
       "4        2018.06.04         6299.0         NaN         NaN  \n",
       "...             ...            ...         ...         ...  \n",
       "25718           NaN            NaN         NaN         NaN  \n",
       "25719           NaN            NaN         NaN         NaN  \n",
       "25720           NaN            NaN         NaN         NaN  \n",
       "25721           NaN            NaN         NaN         NaN  \n",
       "25722           NaN            NaN         NaN         NaN  \n",
       "\n",
       "[25723 rows x 24 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a copy of the original dataset for security"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=original_dataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking for NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we are going to check the two last columns that appears to be only NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since the original data set has 25723 rows and the column Unnamed:22 has 25722  NaN values we can safely drop it.\n"
     ]
    }
   ],
   "source": [
    "print(f'Since the original data set has {cleaned_dataset[\"Unnamed: 22\"].size} rows and the column Unnamed:22 \\\n",
    "has {sum(cleaned_dataset[\"Unnamed: 22\"].isna())}  NaN values we can safely drop it.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since the original data set has 25723 rows and the column Unnamed:23 has 25721  NaN values we can safely drop it.\n"
     ]
    }
   ],
   "source": [
    "print(f'Since the original data set has {cleaned_dataset[\"Unnamed: 23\"].size} rows and the column Unnamed:23 \\\n",
    "has {sum(cleaned_dataset[\"Unnamed: 23\"].isna())}  NaN values we can safely drop it.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.drop(columns=[\"Unnamed: 23\",\"Unnamed: 22\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell bellow we can see that we are not almost near to detect all the missing values. Comparing the number of NaN to the number of data, it seems that there are lots of rows that are empty. Let's check that by creating a new column that shows how many NaN values has each row,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number               17021\n",
       "Date                      19421\n",
       "Year                      19423\n",
       "Type                      19425\n",
       "Country                   19471\n",
       "Area                      19876\n",
       "Location                  19961\n",
       "Activity                  19965\n",
       "Name                      19631\n",
       "Sex                       19986\n",
       "Age                       22252\n",
       "Injury                    19449\n",
       "Fatal (Y/N)               19960\n",
       "Time                      22775\n",
       "Species                   22259\n",
       "Investigator or Source    19438\n",
       "pdf                       19421\n",
       "href formula              19422\n",
       "href                      19421\n",
       "Case Number.1             19421\n",
       "Case Number.2             19421\n",
       "original order            19414\n",
       "dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    17020\n",
       "21     2394\n",
       "1      1516\n",
       "0      1422\n",
       "2      1200\n",
       "3      1196\n",
       "4       540\n",
       "5       293\n",
       "6       102\n",
       "7        26\n",
       "8         7\n",
       "20        7\n",
       "Name: Is_all_NaN, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset[\"Is_all_NaN\"]=cleaned_dataset.isna().sum(axis=1)\n",
    "\n",
    "cleaned_dataset[\"Is_all_NaN\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that there are a great number of columns that have no information or almost no information (columns with 22 or 21). We proceed to remove them. Afther, we will drop the generated \"Is_all_NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.dropna(axis=0, how='any', thresh=20, subset=None, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.drop(columns=\"Is_all_NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still some NaN values, but we will with that later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number                  0\n",
       "Date                         0\n",
       "Year                         0\n",
       "Type                         1\n",
       "Country                      2\n",
       "Area                       103\n",
       "Location                   144\n",
       "Activity                   153\n",
       "Name                        24\n",
       "Sex                        217\n",
       "Age                       1929\n",
       "Injury                       2\n",
       "Fatal (Y/N)                362\n",
       "Time                      2422\n",
       "Species                   2139\n",
       "Investigator or Source       5\n",
       "pdf                          0\n",
       "href formula                 1\n",
       "href                         0\n",
       "Case Number.1                0\n",
       "Case Number.2                0\n",
       "original order               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicated values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are looking for rows that have duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cleaned_dataset.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are not rows with duplicated values. Now we look for columns with duplicated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>ND.0012</td>\n",
       "      <td>Before 19-Jul-1913</td>\n",
       "      <td>ND.0012</td>\n",
       "      <td>ND.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296</th>\n",
       "      <td>ND.0006</td>\n",
       "      <td>Before 1906</td>\n",
       "      <td>ND.0006</td>\n",
       "      <td>ND.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>ND.0005</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>ND.0005</td>\n",
       "      <td>ND.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>ND.0003</td>\n",
       "      <td>1900-1905</td>\n",
       "      <td>ND.0003</td>\n",
       "      <td>ND.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>ND.0001</td>\n",
       "      <td>1845-1853</td>\n",
       "      <td>ND.0001</td>\n",
       "      <td>ND.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5334 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Case Number                Date Case Number.1 Case Number.2\n",
       "0     2018.06.25         25-Jun-2018    2018.06.25    2018.06.25\n",
       "1     2018.06.18         18-Jun-2018    2018.06.18    2018.06.18\n",
       "2     2018.06.09         09-Jun-2018    2018.06.09    2018.06.09\n",
       "3     2018.06.08         08-Jun-2018    2018.06.08    2018.06.08\n",
       "4     2018.06.04         04-Jun-2018    2018.06.04    2018.06.04\n",
       "...          ...                 ...           ...           ...\n",
       "6290     ND.0012  Before 19-Jul-1913       ND.0012       ND.0012\n",
       "6296     ND.0006         Before 1906       ND.0006       ND.0006\n",
       "6297     ND.0005         Before 1903       ND.0005       ND.0005\n",
       "6299     ND.0003           1900-1905       ND.0003       ND.0003\n",
       "6301     ND.0001           1845-1853       ND.0001       ND.0001\n",
       "\n",
       "[5334 rows x 4 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset[['Case Number','Date','Case Number.1','Case Number.2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.drop(columns=['Case Number.1','Case Number.2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with \"Case Number\" it was pretty easy to compare by sight, but it is more difficult to compare URLs by sight, so we will do it by checking with boolean logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     5282\n",
       "False      52\n",
       "dtype: int64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cleaned_dataset['href formula']==cleaned_dataset['href']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that both columns are the same but some mistakes had been made. Nonetheless, we cannot drop a column arbitrarily, so lets check the values that are not equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  href  \\\n",
      "50   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
      "96   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
      "131  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
      "133  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
      "141  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
      "\n",
      "                                          href formula  \n",
      "50   http://sharkattackfile.net/spreadsheets/pdf_di...  \n",
      "96   http://sharkattackfile.net/spreadsheets/pdf_di...  \n",
      "131  http://sharkattackfile.net/spreadsheets/pdf_di...  \n",
      "133  http://sharkattackfile.net/spreadsheets/pdf_di...  \n",
      "141  http://sharkattackfile.net/spreadsheets/pdf_di...  \n"
     ]
    }
   ],
   "source": [
    "pprint(cleaned_dataset[['href','href formula']].loc[cleaned_dataset['href']!=cleaned_dataset['href formula']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing the columns that have different values, we find that none of the URLs are operative anymore. The same is true for the columns that have equal values. This column can be dropped without losing any practical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.drop(columns=['href','href formula'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'pdf' is a column listing reports files to which we do not hace access, so there is not usefull information for us there. On the other hand 'original order' is a column of integer numbers (formated as floats) that it is just de order in which the data were stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.drop(columns=['pdf','original order'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we search for duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are finished (at least by the moment) with deleting rows and columns we are going to reset the dataframe indexes in sake of clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistency of the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we are going to check whether each column has usefull and well formated information or no. This only can be done in a column by column basis, since no general criteria can be applied. Also, we will check if the datatype is the appropiate for this kind of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
       "       'Species ', 'Investigator or Source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1957                    10\n",
       "1950                     6\n",
       "05-Oct-2003              5\n",
       "1958                     5\n",
       "1970s                    5\n",
       "                        ..\n",
       "Reported 16-Aug-1951     1\n",
       "Reported 20-Dec-1998     1\n",
       "18-Oct-1887              1\n",
       "25-Apr-1924              1\n",
       "16-Aug-1999              1\n",
       "Name: Date, Length: 4652, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Date'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date column doesn't seem to have well formatted data. There is some uncompleted information about dates, but it still can be usefull in the future. Let's check next columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Year column is a more simple column and looks better than date column. However, when we check the minimun of the dataset, we have 0 values. Since we can hardly believe that we have data from year 0, let's try to complete this column with information from \"Date\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015.0    139\n",
       "2017.0    127\n",
       "2011.0    124\n",
       "2016.0    123\n",
       "2014.0    116\n",
       "         ... \n",
       "1703.0      1\n",
       "1859.0      1\n",
       "1779.0      1\n",
       "1748.0      1\n",
       "1816.0      1\n",
       "Name: Year, Length: 201, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5253         Ca. 336.B.C..\n",
       "5254          Ca. 725 B.C.\n",
       "5255          1990 or 1991\n",
       "5256           Before 2016\n",
       "5257       Before Oct-2009\n",
       "               ...        \n",
       "5329    Before 19-Jul-1913\n",
       "5330           Before 1906\n",
       "5331           Before 1903\n",
       "5332             1900-1905\n",
       "5333             1845-1853\n",
       "Name: Date, Length: 81, dtype: object"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Date'].loc[cleaned_dataset['Year']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is some related information in the column Date when Year is 0, but something comes to the eye. All the data that has 0 in year are acumulated at the end of the dataset(You can see this by looking to the indexes). Seems that those data are added at posteriori and has no consistency with the dataset. We will make further comprobations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5253 values with a value different from 0 grouped in 200 categories (which is a very reasonable number for a period of time)\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {cleaned_dataset[\"Year\"].loc[cleaned_dataset[\"Year\"]!=0].size} values with a value different from 0 grouped in {cleaned_dataset[\"Year\"].loc[cleaned_dataset[\"Year\"]!=0].value_counts().size} categories (which is a very reasonable number for a period of time)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 81 values with a value equal to 0 from a total sample size of 5334\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {cleaned_dataset[\"Year\"].loc[cleaned_dataset[\"Year\"]==0].size} values with a value equal to 0 from a total sample size of {cleaned_dataset[\"Year\"].size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that those data are not realiable and we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset[cleaned_dataset.Year!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also Year data need to be casted to integer values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset['Year']=cleaned_dataset['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the column 'Type' we can see that values are razonably well categorized except little exceptions that can be easily fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unprovoked      4001\n",
       "Provoked         515\n",
       "Invalid          376\n",
       "Boating          148\n",
       "Sea Disaster     107\n",
       "Boat             102\n",
       "Questionable       2\n",
       "Boatomg            1\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset['Type']=cleaned_dataset['Type'].replace('Boat','Boating')\n",
    "cleaned_dataset['Type']=cleaned_dataset['Type'].replace('Boatomg','Boating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unprovoked      4001\n",
       "Provoked         515\n",
       "Invalid          376\n",
       "Boating          251\n",
       "Sea Disaster     107\n",
       "Questionable       2\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Name' column doesn't seem to have many usefull information. Its two more frequent value are gender (which is stored in other column), not name. Also, particular names are not important for statistical questions we are trying to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male              423\n",
       "female             82\n",
       "boy                13\n",
       "2 males            10\n",
       "child               6\n",
       "                 ... \n",
       "Kerry Keyton        1\n",
       "Wilber Wood         1\n",
       "Jake Swaffer        1\n",
       "Rod Stanley         1\n",
       "Eloise Tavares      1\n",
       "Name: Name, Length: 4612, dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.drop(columns='Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sex column is pretty well categorized but some data can be rescued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M      4454\n",
       "F       578\n",
       "M         2\n",
       "lli       1\n",
       ".         1\n",
       "N         1\n",
       "Name: Sex , dtype: int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Sex '].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset['Sex ']=cleaned_dataset['Sex '].replace('N','F')\n",
    "cleaned_dataset['Sex ']=cleaned_dataset['Sex '].replace('M ','M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>2004.11.11.b</td>\n",
       "      <td>11-Nov-2004</td>\n",
       "      <td>2004</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Bunkers, Humboldt Bay, Eureka, Humboldt County</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>lli</td>\n",
       "      <td>38</td>\n",
       "      <td>Lacerations to hand, knee &amp; thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>13h30</td>\n",
       "      <td>5.5 m [18'] white shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Case Number         Date  Year        Type Country        Area  \\\n",
       "1543  2004.11.11.b  11-Nov-2004  2004  Unprovoked     USA  California   \n",
       "\n",
       "                                            Location Activity Sex  Age  \\\n",
       "1543  Bunkers, Humboldt Bay, Eureka, Humboldt County  Surfing  lli  38   \n",
       "\n",
       "                                  Injury Fatal (Y/N)   Time  \\\n",
       "1543  Lacerations to hand, knee & thigh            N  13h30   \n",
       "\n",
       "                     Species             Investigator or Source  \n",
       "1543  5.5 m [18'] white shark  R. Collier, GSAF                  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset.loc[cleaned_dataset['Sex ']=='lli']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>1908.06.02.R</td>\n",
       "      <td>Reported 02-Jun-1908</td>\n",
       "      <td>1908</td>\n",
       "      <td>Sea Disaster</td>\n",
       "      <td>PAPUA NEW GUINEA</td>\n",
       "      <td>New Britain</td>\n",
       "      <td>Matupi</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remains of 3 humans recovered from shark, but ...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Allegedly a 33-foot shark</td>\n",
       "      <td>Taranaki Herald, 6/2/1908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Case Number                  Date  Year          Type  \\\n",
       "4778  1908.06.02.R  Reported 02-Jun-1908  1908  Sea Disaster   \n",
       "\n",
       "               Country         Area Location Activity Sex   Age  \\\n",
       "4778  PAPUA NEW GUINEA  New Britain   Matupi        .    .  NaN   \n",
       "\n",
       "                                                 Injury Fatal (Y/N) Time  \\\n",
       "4778  Remains of 3 humans recovered from shark, but ...           Y  NaN   \n",
       "\n",
       "                       Species      Investigator or Source  \n",
       "4778  Allegedly a 33-foot shark  Taranaki Herald, 6/2/1908  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset.loc[cleaned_dataset['Sex ']=='.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset['Sex ']=cleaned_dataset['Sex '].replace('lli','M')\n",
    "cleaned_dataset=cleaned_dataset[cleaned_dataset['Sex ']!='.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N          3843\n",
       "Y          1017\n",
       "UNKNOWN      22\n",
       " N            7\n",
       "2017          1\n",
       "M             1\n",
       "Name: Fatal (Y/N), dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Fatal (Y/N)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset['Fatal (Y/N)']=cleaned_dataset['Fatal (Y/N)'].replace(' N','N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset['Fatal (Y/N)']=cleaned_dataset['Fatal (Y/N)'].replace('M','N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>2012.06.10</td>\n",
       "      <td>10-Jun-2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>ITALY</td>\n",
       "      <td>Sardinia</td>\n",
       "      <td>Muravera</td>\n",
       "      <td>Attempting to rescue an injured &amp; beached shark</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>Lower left leg injured PROVOKED ACCIDENT</td>\n",
       "      <td>2017</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Blue shark, 2.5m</td>\n",
       "      <td>D. Puddo, 6/11/2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case Number         Date  Year      Type Country      Area  Location  \\\n",
       "743  2012.06.10  10-Jun-2012  2012  Provoked   ITALY  Sardinia  Muravera   \n",
       "\n",
       "                                            Activity Sex  Age  \\\n",
       "743  Attempting to rescue an injured & beached shark    M  57   \n",
       "\n",
       "                                       Injury Fatal (Y/N)     Time  \\\n",
       "743  Lower left leg injured PROVOKED ACCIDENT        2017  Morning   \n",
       "\n",
       "             Species  Investigator or Source  \n",
       "743  Blue shark, 2.5m    D. Puddo, 6/11/2012  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset.loc[cleaned_dataset['Fatal (Y/N)']=='2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset['Fatal (Y/N)']=cleaned_dataset['Fatal (Y/N)'].replace('2017','N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
