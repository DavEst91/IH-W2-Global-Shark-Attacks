{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import re\n",
    "import os\n",
    "\n",
    "from src.my_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset=pd.read_csv('input/attacks.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first sight we can see a 23 columns dataset. Some of them are dates, some of them are categorical data and links to files than can be useful if important information is missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Arrawarra Headland</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>2018.06.08-Arrawarra.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Colima</td>\n",
       "      <td>La Ticla</td>\n",
       "      <td>Free diving</td>\n",
       "      <td>Gustavo Ramos</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>Tiger shark, 3m</td>\n",
       "      <td>A .Kipper</td>\n",
       "      <td>2018.06.04-Ramos.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case Number         Date    Year        Type    Country             Area  \\\n",
       "0  2018.06.25  25-Jun-2018  2018.0     Boating        USA       California   \n",
       "1  2018.06.18  18-Jun-2018  2018.0  Unprovoked        USA          Georgia   \n",
       "2  2018.06.09  09-Jun-2018  2018.0     Invalid        USA           Hawaii   \n",
       "3  2018.06.08  08-Jun-2018  2018.0  Unprovoked  AUSTRALIA  New South Wales   \n",
       "4  2018.06.04  04-Jun-2018  2018.0    Provoked     MEXICO           Colima   \n",
       "\n",
       "                         Location     Activity             Name Sex   ...  \\\n",
       "0     Oceanside, San Diego County     Paddling      Julie Wolfe    F  ...   \n",
       "1  St. Simon Island, Glynn County     Standing  Adyson McNeely     F  ...   \n",
       "2                    Habush, Oahu      Surfing      John Denges    M  ...   \n",
       "3              Arrawarra Headland      Surfing             male    M  ...   \n",
       "4                        La Ticla  Free diving   Gustavo Ramos     M  ...   \n",
       "\n",
       "          Species           Investigator or Source                       pdf  \\\n",
       "0      White shark                R. Collier, GSAF      2018.06.25-Wolfe.pdf   \n",
       "1              NaN  K.McMurray, TrackingSharks.com    2018.06.18-McNeely.pdf   \n",
       "2              NaN  K.McMurray, TrackingSharks.com     2018.06.09-Denges.pdf   \n",
       "3        2 m shark                  B. Myatt, GSAF  2018.06.08-Arrawarra.pdf   \n",
       "4  Tiger shark, 3m                       A .Kipper      2018.06.04-Ramos.pdf   \n",
       "\n",
       "                                        href formula  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href Case Number.1  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.25   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.18   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.09   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.08   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.04   \n",
       "\n",
       "  Case Number.2 original order Unnamed: 22 Unnamed: 23  \n",
       "0    2018.06.25         6303.0         NaN         NaN  \n",
       "1    2018.06.18         6302.0         NaN         NaN  \n",
       "2    2018.06.09         6301.0         NaN         NaN  \n",
       "3    2018.06.08         6300.0         NaN         NaN  \n",
       "4    2018.06.04         6299.0         NaN         NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a copy of the original dataset for security"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=original_dataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking for NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we are going to check the two last columns that appears to be only NaN values\n",
    "\n",
    "Since the original data set has 25723 rows and the columns Unnamed:22 and Unnamed:23 have 25722  NaN values we can safely drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25722"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cleaned_dataset['Unnamed: 22'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.drop(columns=[\"Unnamed: 23\",\"Unnamed: 22\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell bellow we can see that we are not almost near to detect all the missing values. Comparing the number of NaN to the number of data, it seems that there are lots of rows that are empty. Let's check that by creating a new column that shows how many NaN values has each row,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number               17021\n",
       "Date                      19421\n",
       "Year                      19423\n",
       "Type                      19425\n",
       "Country                   19471\n",
       "Area                      19876\n",
       "Location                  19961\n",
       "Activity                  19965\n",
       "Name                      19631\n",
       "Sex                       19986\n",
       "Age                       22252\n",
       "Injury                    19449\n",
       "Fatal (Y/N)               19960\n",
       "Time                      22775\n",
       "Species                   22259\n",
       "Investigator or Source    19438\n",
       "pdf                       19421\n",
       "href formula              19422\n",
       "href                      19421\n",
       "Case Number.1             19421\n",
       "Case Number.2             19421\n",
       "original order            19414\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    17020\n",
       "21     2394\n",
       "1      1516\n",
       "0      1422\n",
       "2      1200\n",
       "3      1196\n",
       "4       540\n",
       "5       293\n",
       "6       102\n",
       "7        26\n",
       "8         7\n",
       "20        7\n",
       "Name: Is_all_NaN, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset[\"Is_all_NaN\"]=cleaned_dataset.isna().sum(axis=1)\n",
    "\n",
    "cleaned_dataset[\"Is_all_NaN\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that there are a great number of columns that have no information or almost no information (columns with 22 or 21). We proceed to remove them. Afther, we will drop the generated \"Is_all_NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.dropna(axis=0, how='any', thresh=20, subset=None, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.drop(columns=\"Is_all_NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still some NaN values, but we will with that later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number                  0\n",
       "Date                         0\n",
       "Year                         0\n",
       "Type                         1\n",
       "Country                      2\n",
       "Area                       103\n",
       "Location                   144\n",
       "Activity                   153\n",
       "Name                        24\n",
       "Sex                        217\n",
       "Age                       1929\n",
       "Injury                       2\n",
       "Fatal (Y/N)                362\n",
       "Time                      2422\n",
       "Species                   2139\n",
       "Investigator or Source       5\n",
       "pdf                          0\n",
       "href formula                 1\n",
       "href                         0\n",
       "Case Number.1                0\n",
       "Case Number.2                0\n",
       "original order               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicated values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are looking for rows that have duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cleaned_dataset.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are not rows with duplicated values. Now we look for columns with duplicated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>ND.0012</td>\n",
       "      <td>Before 19-Jul-1913</td>\n",
       "      <td>ND.0012</td>\n",
       "      <td>ND.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296</th>\n",
       "      <td>ND.0006</td>\n",
       "      <td>Before 1906</td>\n",
       "      <td>ND.0006</td>\n",
       "      <td>ND.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>ND.0005</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>ND.0005</td>\n",
       "      <td>ND.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>ND.0003</td>\n",
       "      <td>1900-1905</td>\n",
       "      <td>ND.0003</td>\n",
       "      <td>ND.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>ND.0001</td>\n",
       "      <td>1845-1853</td>\n",
       "      <td>ND.0001</td>\n",
       "      <td>ND.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5334 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Case Number                Date Case Number.1 Case Number.2\n",
       "0     2018.06.25         25-Jun-2018    2018.06.25    2018.06.25\n",
       "1     2018.06.18         18-Jun-2018    2018.06.18    2018.06.18\n",
       "2     2018.06.09         09-Jun-2018    2018.06.09    2018.06.09\n",
       "3     2018.06.08         08-Jun-2018    2018.06.08    2018.06.08\n",
       "4     2018.06.04         04-Jun-2018    2018.06.04    2018.06.04\n",
       "...          ...                 ...           ...           ...\n",
       "6290     ND.0012  Before 19-Jul-1913       ND.0012       ND.0012\n",
       "6296     ND.0006         Before 1906       ND.0006       ND.0006\n",
       "6297     ND.0005         Before 1903       ND.0005       ND.0005\n",
       "6299     ND.0003           1900-1905       ND.0003       ND.0003\n",
       "6301     ND.0001           1845-1853       ND.0001       ND.0001\n",
       "\n",
       "[5334 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset[['Case Number','Date','Case Number.1','Case Number.2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.drop(columns=['Case Number.1','Case Number.2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with \"Case Number\" it was pretty easy to compare by sight, but it is more difficult to compare URLs by sight, so we will do it by checking with boolean logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     5282\n",
       "False      52\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cleaned_dataset['href formula']==cleaned_dataset['href']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that both columns are the same but some mistakes had been made. Nonetheless, we cannot drop a column arbitrarily, so lets check the values that are not equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  href  \\\n",
      "50   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
      "96   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
      "131  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
      "133  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
      "141  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
      "\n",
      "                                          href formula  \n",
      "50   http://sharkattackfile.net/spreadsheets/pdf_di...  \n",
      "96   http://sharkattackfile.net/spreadsheets/pdf_di...  \n",
      "131  http://sharkattackfile.net/spreadsheets/pdf_di...  \n",
      "133  http://sharkattackfile.net/spreadsheets/pdf_di...  \n",
      "141  http://sharkattackfile.net/spreadsheets/pdf_di...  \n"
     ]
    }
   ],
   "source": [
    "pprint(cleaned_dataset[['href','href formula']].loc[cleaned_dataset['href']!=cleaned_dataset['href formula']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing the columns that have different values, we find that none of the URLs are operative anymore. The same is true for the columns that have equal values. This column can be dropped without losing any practical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.drop(columns=['href','href formula'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'pdf' is a column listing reports files to which we do not hace access, so there is not usefull information for us there. On the other hand 'original order' is a column of integer numbers (formated as floats) that it is just de order in which the data were stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.drop(columns=['pdf','original order'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we search for duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are finished (at least by the moment) with deleting rows and columns we are going to reset the dataframe indexes in sake of clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistency of the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we are going to check whether each column has usefull and well formated information or no. This only can be done in a column by column basis, since no general criteria can be applied. Also, we will check if the datatype is the appropiate for this kind of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
       "       'Species ', 'Investigator or Source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1957                   10\n",
       "1950                    6\n",
       "1970s                   5\n",
       "12-Apr-2001             5\n",
       "28-Jul-1995             5\n",
       "                       ..\n",
       "Reportd 15-Jul-1894     1\n",
       "4-Apr-1970              1\n",
       "09-Dec-1964             1\n",
       "20-Jun-2006             1\n",
       "08-Mar-1938             1\n",
       "Name: Date, Length: 4652, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Date'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date column doesn't seem to have well formatted data. There is some uncompleted information about dates, but it still can be usefull in the future. Let's check next columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Year column is a more simple column and looks better than date column. However, when we check the minimun of the dataset, we have 0 values. Since we can hardly believe that we have data from year 0, let's try to complete this column with information from \"Date\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015.0    139\n",
       "2017.0    127\n",
       "2011.0    124\n",
       "2016.0    123\n",
       "2014.0    116\n",
       "         ... \n",
       "1703.0      1\n",
       "1859.0      1\n",
       "1779.0      1\n",
       "1748.0      1\n",
       "1816.0      1\n",
       "Name: Year, Length: 201, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5253         Ca. 336.B.C..\n",
       "5254          Ca. 725 B.C.\n",
       "5255          1990 or 1991\n",
       "5256           Before 2016\n",
       "5257       Before Oct-2009\n",
       "               ...        \n",
       "5329    Before 19-Jul-1913\n",
       "5330           Before 1906\n",
       "5331           Before 1903\n",
       "5332             1900-1905\n",
       "5333             1845-1853\n",
       "Name: Date, Length: 81, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Date'].loc[cleaned_dataset['Year']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is some related information in the column Date when Year is 0, but something comes to the eye. All the data that has 0 in year are acumulated at the end of the dataset(You can see this by looking to the indexes). Seems that those data are added at posteriori and has no consistency with the dataset. We will make further comprobations\n",
    "\n",
    "There are 5253 values with a value different from 0 grouped in 200 categories (which is a very reasonable number for a period of time) but there are 81 values with a value equal to 0 from a total sample size of 5334\n",
    "\n",
    "It's clear that those data are not realiable and we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset[cleaned_dataset.Year!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also Year data need to be casted to integer values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset['Year']=cleaned_dataset['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the column 'Type' we can see that values are razonably well categorized except little exceptions that can be easily fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unprovoked      4001\n",
       "Provoked         515\n",
       "Invalid          376\n",
       "Boating          148\n",
       "Sea Disaster     107\n",
       "Boat             102\n",
       "Questionable       2\n",
       "Boatomg            1\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset['Type']=cleaned_dataset['Type'].replace('Boat','Boating')\n",
    "cleaned_dataset['Type']=cleaned_dataset['Type'].replace('Boatomg','Boating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unprovoked      4001\n",
       "Provoked         515\n",
       "Invalid          376\n",
       "Boating          251\n",
       "Sea Disaster     107\n",
       "Questionable       2\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Name' column doesn't seem to have many usefull information. Its five more frequent value are not names, but gender or age, qhich are stored in other columns. Also, particular names are not important for statistical questions we are trying to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male               423\n",
       "female              82\n",
       "boy                 13\n",
       "2 males             10\n",
       "child                6\n",
       "                  ... \n",
       "Eva Cameron          1\n",
       "Crisolog Urizar      1\n",
       "Lorraine             1\n",
       "David Lomas          1\n",
       "Luis Hernandez       1\n",
       "Name: Name, Length: 4612, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.drop(columns='Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sex column is pretty well categorized but some data can be rescued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M      4454\n",
       "F       578\n",
       "M         2\n",
       "N         1\n",
       "lli       1\n",
       ".         1\n",
       "Name: Sex , dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Sex '].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset['Sex ']=cleaned_dataset['Sex '].replace('N','F')\n",
    "cleaned_dataset['Sex ']=cleaned_dataset['Sex '].replace('M ','M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>2004.11.11.b</td>\n",
       "      <td>11-Nov-2004</td>\n",
       "      <td>2004</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Bunkers, Humboldt Bay, Eureka, Humboldt County</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>lli</td>\n",
       "      <td>38</td>\n",
       "      <td>Lacerations to hand, knee &amp; thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>13h30</td>\n",
       "      <td>5.5 m [18'] white shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Case Number         Date  Year        Type Country        Area  \\\n",
       "1543  2004.11.11.b  11-Nov-2004  2004  Unprovoked     USA  California   \n",
       "\n",
       "                                            Location Activity Sex  Age  \\\n",
       "1543  Bunkers, Humboldt Bay, Eureka, Humboldt County  Surfing  lli  38   \n",
       "\n",
       "                                  Injury Fatal (Y/N)   Time  \\\n",
       "1543  Lacerations to hand, knee & thigh            N  13h30   \n",
       "\n",
       "                     Species             Investigator or Source  \n",
       "1543  5.5 m [18'] white shark  R. Collier, GSAF                  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset.loc[cleaned_dataset['Sex ']=='lli']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>1908.06.02.R</td>\n",
       "      <td>Reported 02-Jun-1908</td>\n",
       "      <td>1908</td>\n",
       "      <td>Sea Disaster</td>\n",
       "      <td>PAPUA NEW GUINEA</td>\n",
       "      <td>New Britain</td>\n",
       "      <td>Matupi</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remains of 3 humans recovered from shark, but ...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Allegedly a 33-foot shark</td>\n",
       "      <td>Taranaki Herald, 6/2/1908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Case Number                  Date  Year          Type  \\\n",
       "4778  1908.06.02.R  Reported 02-Jun-1908  1908  Sea Disaster   \n",
       "\n",
       "               Country         Area Location Activity Sex   Age  \\\n",
       "4778  PAPUA NEW GUINEA  New Britain   Matupi        .    .  NaN   \n",
       "\n",
       "                                                 Injury Fatal (Y/N) Time  \\\n",
       "4778  Remains of 3 humans recovered from shark, but ...           Y  NaN   \n",
       "\n",
       "                       Species      Investigator or Source  \n",
       "4778  Allegedly a 33-foot shark  Taranaki Herald, 6/2/1908  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset.loc[cleaned_dataset['Sex ']=='.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset['Sex ']=cleaned_dataset['Sex '].replace('lli','M')\n",
    "cleaned_dataset=cleaned_dataset[cleaned_dataset['Sex ']!='.']\n",
    "cleaned_dataset=cleaned_dataset.rename(columns={'Sex ':'Sex'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Age' column have some data values that can be fixed and a quite important cuantity of NaN wrong formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in cleaned_dataset.index:\n",
    "    x=cleaned_dataset.loc[i,'Age']\n",
    "    list_matches=re.findall(r'\\d{1,2}',str(x))\n",
    "    if len(list_matches)>=1:\n",
    "        cleaned_dataset.loc[i,'Age']=int(sum(map(int,list_matches))/len(list_matches))\n",
    "    else:\n",
    "        cleaned_dataset.loc[i,'Age']=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Injury' column has 3262 different values with no coding or standard, so we cannot extract statistical information from here. Anyhow, it will remain because it does have information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FATAL                                                          555\n",
       "Foot bitten                                                     78\n",
       "No injury                                                       67\n",
       "Leg bitten                                                      61\n",
       "Survived                                                        52\n",
       "                                                              ... \n",
       "FATAL, both arms severed                                         1\n",
       "Feet lacerated                                                   1\n",
       "3 toes severed                                                   1\n",
       "Bumped, then knee bitten                                         1\n",
       "Laceration to left calf from hooked shark PROVOKED INCIDENT      1\n",
       "Name: Injury, Length: 3262, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Injury'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Fatal (Y/N)' column is mostly well codificated but need some fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N          3851\n",
       "Y          1017\n",
       "UNKNOWN      22\n",
       "2017          1\n",
       "Name: Fatal (Y/N), dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Fatal (Y/N)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset['Fatal (Y/N)']=cleaned_dataset['Fatal (Y/N)'].replace(' N','N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset['Fatal (Y/N)']=cleaned_dataset['Fatal (Y/N)'].replace('M','N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>2012.06.10</td>\n",
       "      <td>10-Jun-2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>ITALY</td>\n",
       "      <td>Sardinia</td>\n",
       "      <td>Muravera</td>\n",
       "      <td>Attempting to rescue an injured &amp; beached shark</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>Lower left leg injured PROVOKED ACCIDENT</td>\n",
       "      <td>2017</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Blue shark, 2.5m</td>\n",
       "      <td>D. Puddo, 6/11/2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case Number         Date  Year      Type Country      Area  Location  \\\n",
       "743  2012.06.10  10-Jun-2012  2012  Provoked   ITALY  Sardinia  Muravera   \n",
       "\n",
       "                                            Activity Sex Age  \\\n",
       "743  Attempting to rescue an injured & beached shark   M  57   \n",
       "\n",
       "                                       Injury Fatal (Y/N)     Time  \\\n",
       "743  Lower left leg injured PROVOKED ACCIDENT        2017  Morning   \n",
       "\n",
       "             Species  Investigator or Source  \n",
       "743  Blue shark, 2.5m    D. Puddo, 6/11/2012  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset.loc[cleaned_dataset['Fatal (Y/N)']=='2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset['Fatal (Y/N)']=cleaned_dataset['Fatal (Y/N)'].replace('2017','N')\n",
    "cleaned_dataset=cleaned_dataset.rename(columns={'Fatal (Y/N)':'Fatal'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Time' values are not standarized, so we will try to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Afternoon                         181\n",
       "11h00                             127\n",
       "Morning                           120\n",
       "15h00                             108\n",
       "12h00                             108\n",
       "                                 ... \n",
       "19h00 / 20h00                       1\n",
       "Before daybreak                     1\n",
       "14h30 / 15h30                       1\n",
       "Sometime between 06h00 & 08hoo      1\n",
       "15h56                               1\n",
       "Name: Time, Length: 360, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset['Time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset.Time=cleaned_dataset.Time.apply(assign_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Species' column is not pretended to be used in further analysis, so we will drop it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.drop(columns=['Species '])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'investigator or source' column has no use for statistical purposes but still has information that does have ofr individual cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset=cleaned_dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This, our dataset is ready to be exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset.to_csv('output/Sharks_attacks_cleaned.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
